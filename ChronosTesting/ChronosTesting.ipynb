{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93137273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lexei\\tf-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import pandas as pd\n",
    "from chronos import Chronos2Pipeline\n",
    "import matplotlib.pyplot as plt  \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b976cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host_name (anonymized)\n",
      "1025    1\n",
      "1046    1\n",
      "1049    1\n",
      "1056    1\n",
      "1084    1\n",
      "       ..\n",
      "9945    1\n",
      "9950    1\n",
      "9972    1\n",
      "9984    1\n",
      "9991    1\n",
      "Length: 1000, dtype: int64\n",
      "Empty DataFrame\n",
      "Columns: [Event Id, Last Seen, host_name (anonymized), model_name, hardware_make, auth_username (anonymized), group_id, tenant_id, platform, metric_category, measure_name, time, p90_processor_time, avg_processor_time, max_cpu_usage, p90_memory_utilization, avg_memory_utilization, max_memory_usage, p10_battery_health, avg_battery_health, cpu_count, memory_count, memory_size_gb, driver_vendor, os, driver_version, driver_date, os_version, driver, agent_id, performance_status, device_status, max_battery_temperature, avg_battery_temperature, p90_battery_temperature, avg_cpu_temp, p90_cpu_temp, avg_battery_discharge, p90_battery_discharge, avg_boot_time, p90_boot_time, uptime_days, total_app_crash]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "context_df = pd.read_csv(\"telemetry_anonymized.csv\", parse_dates=[\"Last Seen\"])\n",
    "\n",
    "context_df = context_df.sort_values([\"host_name (anonymized)\", \"Last Seen\"])\n",
    "\n",
    "# Count rows per series\n",
    "series_lengths = context_df.groupby(\"host_name (anonymized)\").size()\n",
    "\n",
    "print(series_lengths)\n",
    "# Keep only series with >= 3 rows\n",
    "valid_ids = series_lengths[series_lengths >= 3].index\n",
    "context_df = context_df[context_df[\"host_name (anonymized)\"].isin(valid_ids)]\n",
    "\n",
    "print(context_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c3fc26",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m pipeline = Chronos2Pipeline.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mamazon/chronos-2\u001b[39m\u001b[33m\"\u001b[39m, device_map=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# changed to cpu since I don't have a gpu\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load historical target values and past values of covariates\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#context_df = pd.read_parquet(\"https://autogluon.s3.amazonaws.com/datasets/timeseries/electricity_price/train.parquet\")\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Generate predictions with covariates\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m pred_df = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfuture_df\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprediction_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of steps to forecast\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantile_levels\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Quantiles for probabilistic forecast\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mid_column\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvent Id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Column identifying different time series\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimestamp_column\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLast Seen\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Column with datetime information\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhost_name (anonymized)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Column(s) with time series values to predict\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lexei\\tf-env\\Lib\\site-packages\\chronos\\chronos2\\pipeline.py:892\u001b[39m, in \u001b[36mChronos2Pipeline.predict_df\u001b[39m\u001b[34m(self, df, future_df, id_column, timestamp_column, target, prediction_length, quantile_levels, batch_size, context_length, cross_learning, validate_inputs, **predict_kwargs)\u001b[39m\n\u001b[32m    889\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    890\u001b[39m     target = [target]\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m inputs, original_order, prediction_timestamps = \u001b[43mconvert_df_input_to_list_of_dicts_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfuture_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfuture_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mid_column\u001b[49m\u001b[43m=\u001b[49m\u001b[43mid_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimestamp_column\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimestamp_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprediction_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprediction_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[38;5;66;03m# Generate forecasts\u001b[39;00m\n\u001b[32m    903\u001b[39m quantiles, mean = \u001b[38;5;28mself\u001b[39m.predict_quantiles(\n\u001b[32m    904\u001b[39m     inputs=inputs,\n\u001b[32m    905\u001b[39m     prediction_length=prediction_length,\n\u001b[32m   (...)\u001b[39m\u001b[32m    911\u001b[39m     **predict_kwargs,\n\u001b[32m    912\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lexei\\tf-env\\Lib\\site-packages\\chronos\\df_utils.py:246\u001b[39m, in \u001b[36mconvert_df_input_to_list_of_dicts_input\u001b[39m\u001b[34m(df, future_df, target_columns, prediction_length, id_column, timestamp_column, validate_inputs)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validate_inputs:\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     df, future_df, freq, series_lengths, original_order = \u001b[43mvalidate_df_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfuture_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfuture_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mid_column\u001b[49m\u001b[43m=\u001b[49m\u001b[43mid_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimestamp_column\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimestamp_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprediction_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprediction_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    255\u001b[39m     \u001b[38;5;66;03m# Get the original order of time series IDs\u001b[39;00m\n\u001b[32m    256\u001b[39m     original_order = df[id_column].unique()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lexei\\tf-env\\Lib\\site-packages\\chronos\\df_utils.py:174\u001b[39m, in \u001b[36mvalidate_df_inputs\u001b[39m\u001b[34m(df, future_df, target_columns, prediction_length, id_column, timestamp_column)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(all_freqs)) > \u001b[32m1\u001b[39m:\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll time series must have the same frequency\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m inferred_freq = \u001b[43mall_freqs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;66;03m# Sort future_df if provided and validate its series lengths\u001b[39;00m\n\u001b[32m    177\u001b[39m future_series_lengths = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "pipeline = Chronos2Pipeline.from_pretrained(\"amazon/chronos-2\", device_map=\"cpu\") # changed to cpu since I don't have a gpu\n",
    "\n",
    "# Load historical target values and past values of covariates\n",
    "#context_df = pd.read_parquet(\"https://autogluon.s3.amazonaws.com/datasets/timeseries/electricity_price/train.parquet\")\n",
    "\n",
    "# (Optional) Load future values of covariates\n",
    "#test_df = pd.read_parquet(\"https://autogluon.s3.amazonaws.com/datasets/timeseries/electricity_price/test.parquet\")\n",
    "#future_df = test_df.drop(columns=\"target\")\n",
    "\n",
    "# Generate predictions with covariates\n",
    "pred_df = pipeline.predict_df(\n",
    "    context_df,\n",
    "    future_df = None,\n",
    "    prediction_length=24,  # Number of steps to forecast\n",
    "    quantile_levels=[0.1, 0.5, 0.9],  # Quantiles for probabilistic forecast\n",
    "    id_column=\"Event Id\",  # Column identifying different time series\n",
    "    timestamp_column=\"Last Seen\",  # Column with datetime information\n",
    "    target=\"host_name (anonymized)\",  # Column(s) with time series values to predict\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
